{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# define the R-GCN model\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, num_rels, num_bases):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.hid_feats = hid_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.num_rels = num_rels\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        # define the weight matrices for each relation\n",
    "        self.w = nn.ModuleList()\n",
    "        for i in range(num_rels):\n",
    "            if num_bases > 0:\n",
    "                self.w.append(nn.Linear(in_feats, num_bases))\n",
    "            else:\n",
    "                self.w.append(nn.Linear(in_feats, hid_feats))\n",
    "        self.v = nn.Linear(hid_feats * num_rels, out_feats)\n",
    "\n",
    "    def forward(self, g, h, r, norm):\n",
    "        # compute the embeddings for each relation\n",
    "        h = h.float()\n",
    "        weight_list = []\n",
    "        for i in range(self.num_rels):\n",
    "            if self.num_bases > 0:\n",
    "                weight = self.w[i](h).view(-1, self.hid_feats, self.num_bases)\n",
    "                weight = torch.matmul(r[i], weight).view(-1, self.hid_feats * self.num_bases)\n",
    "            else:\n",
    "                weight = torch.matmul(r[i], self.w[i](h))\n",
    "            weight_list.append(weight)\n",
    "\n",
    "        # sum the embeddings over all relations\n",
    "        h = torch.cat(weight_list, dim=1)\n",
    "        h = self.v(h)\n",
    "\n",
    "        # normalize the embeddings\n",
    "        h = h * norm\n",
    "        return h\n",
    "\n",
    "# set the hyperparameters\n",
    "in_feats = 10\n",
    "hid_feats = 16\n",
    "out_feats = 1\n",
    "num_rels = 2\n",
    "num_bases = 2\n",
    "lr = 0.01\n",
    "n_epochs = 50\n",
    "\n",
    "# generate a random graph with 100 nodes and 1000 edges\n",
    "g = dgl.rand_graph(100, 1000)\n",
    "src, dst = g.edges()\n",
    "labels = g.adjacency_matrix().to_dense()[src, dst]\n",
    "\n",
    "# generate random features for each node\n",
    "h = torch.randn(g.num_nodes(), in_feats)\n",
    "\n",
    "# compute the normalization factor for each node\n",
    "deg = g.in_degrees().float().clamp(min=1)\n",
    "norm = torch.pow(deg, -0.5)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_mask = torch.zeros(g.num_edges(), dtype=torch.bool)\n",
    "test_mask = torch.zeros(g.num_edges(), dtype=torch.bool)\n",
    "train_mask[:800] = True\n",
    "test_mask[800:] = True\n",
    "train_idx = torch.nonzero(train_mask).squeeze()\n",
    "test_idx = torch.nonzero(test_mask).squeeze()\n",
    "\n",
    "# create the R-GCN model and define the loss function and optimizer\n",
    "model = RGCN(in_feats, hid_feats, out_feats, num_rels, num_bases)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# train the model\n",
    "train_loss_list = []\n",
    "for epoch in range(n_epochs):\n",
    "    # set the model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(g, h, g.edata['type'], norm)\n",
    "    loss = criterion(logits[train_idx], labels[train_idx].float())\n",
    "\n",
    "    #\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        # set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(g, h, g.edata['type'], norm)\n",
    "\n",
    "        # compute the loss and accuracy\n",
    "        test_loss = criterion(logits[test_idx], labels[test_idx].float())\n",
    "        test_pred = torch.sigmoid(logits[test_idx])\n",
    "        test_auc = roc_auc_score(labels[test_idx].numpy(), test_pred.numpy())\n",
    "\n",
    "        # append the loss to the list\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        # print the progress\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test AUC: {:.4f}'.format(epoch+1, n_epochs, loss.item(), test_loss.item(), test_auc))\n",
    "\n",
    "# plot the training loss over time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, n_epochs+1), train_loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
