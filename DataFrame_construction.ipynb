{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "path = f'/media/EXTHDD/UnfollowData/WeeklySnapshots/round1-15/round15/Tweets'\n",
    "os.chdir(path)\n",
    "\n",
    "user_data = []\n",
    "tweet_data = []\n",
    "\n",
    "for file in glob.glob(\"*.pkl\"):\n",
    "    f1 = pd.read_pickle(file)\n",
    "    for j in f1:\n",
    "        user_data.append([\n",
    "            j.get('user').get('id_str', 0),\n",
    "            j.get('user').get('verified', 0),\n",
    "            j.get('user').get('created_at', 0),\n",
    "            j.get('user').get('location', 0),\n",
    "            j.get('user').get('description', 0),\n",
    "            j.get('user').get('profile_image_url_https', 0),\n",
    "            j.get('user').get('listed_count', 0),\n",
    "            j.get('user').get('url', 0),\n",
    "            j.get('user').get('favourites_count', 0),\n",
    "            j.get('user').get('statuses_count', 0)\n",
    "        ])\n",
    "\n",
    "user_columns = ['id_str', 'verified', 'created_at', 'location', 'description',\n",
    "                'profile_image_url_https', 'listed_count', 'url', 'favourites_count', 'statuses_count']\n",
    "\n",
    "user_df = pd.DataFrame(user_data, columns=user_columns)\n",
    "\n",
    "print(user_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df=user_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_user_set1 = pd.read_pickle(\"/media/EXTHDD/UnfollowData/WeeklySnapshots/round1-15/megaUserSet.pkl\")\n",
    "mega_user_str=set()\n",
    "for i in mega_user_set1:\n",
    "    mega_user_str.add(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_id_str_set = set(user_df.id_str)\n",
    "l = [i for i in mega_user_str if i not in user_id_str_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a new DataFrame with the same columns as user_df\n",
    "new_df = pd.DataFrame(columns=user_df.columns)\n",
    "\n",
    "# Set the 'id_str' column to the values in the list l\n",
    "new_df['id_str'] = l\n",
    "\n",
    "# Fill the other columns with 0\n",
    "new_df.fillna(0, inplace=True)\n",
    "\n",
    "# Concatenate the new DataFrame with user_df\n",
    "user_df_extended = pd.concat([user_df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the 'created_at' column to datetime format\n",
    "user_df_extended['created_at'] = pd.to_datetime(user_df_extended['created_at'], errors='coerce', format='%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "# Extract the year from the 'created_at' column\n",
    "user_df_extended['year'] = user_df_extended['created_at'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended=user_df_extended.drop(columns={'created_at'})\n",
    "user_df_extended.year.fillna(2012, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended['profile_image_url_https'] = user_df_extended['profile_image_url_https'].apply(lambda x: 1 if isinstance(x, str) and x.strip() else 0)\n",
    "user_df_extended['url'] = user_df_extended['url'].apply(lambda x: 1 if isinstance(x, str) and x.strip() else 0)\n",
    "user_df_extended['location'] = user_df_extended['location'].apply(lambda x: 1 if isinstance(x, str) and x.strip() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of non-zero 'listed_count' values\n",
    "mean_listed_count = user_df_extended[user_df_extended['listed_count'] != 0]['listed_count'].mean()\n",
    "\n",
    "# Replace 0 values in the 'listed_count' column with the computed mean\n",
    "user_df_extended['listed_count'] = user_df_extended['listed_count'].replace(0, mean_listed_count)\n",
    "# Compute the mean of non-zero 'listed_count' values\n",
    "mean_listed_count = user_df_extended[user_df_extended['favourites_count'] != 0]['favourites_count'].mean()\n",
    "\n",
    "# Replace 0 values in the 'listed_count' column with the computed mean\n",
    "user_df_extended['favourites_count'] = user_df_extended['favourites_count'].replace(0, mean_listed_count)\n",
    "\n",
    "# Compute the mean of non-zero 'listed_count' values\n",
    "mean_listed_count = user_df_extended[user_df_extended['statuses_count'] != 0]['statuses_count'].mean()\n",
    "\n",
    "# Replace 0 values in the 'listed_count' column with the computed mean\n",
    "user_df_extended['statuses_count'] = user_df_extended['statuses_count'].replace(0, mean_listed_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended.to_csv(\"/home/leanna/unfollow_prediction/Markov_chain/dd5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended1=pd.DataFrame(pd.read_csv(\"/home/leanna/unfollow_prediction/Markov_chain/LIWC-22 Results - dd - LIWC Analysis (1).csv\", low_memory = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended1= user_df_extended1.drop(columns={'Unnamed: 0','ColumnID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Custom function to find the top 2 highest scores\n",
    "def find_top_two(row):\n",
    "    return row.nlargest(2).index\n",
    "\n",
    "# Convert the relevant columns to a numeric data type\n",
    "columns = ['Culture', 'politic', 'ethnicity', 'tech', 'Lifestyle', 'leisure', 'home', 'work',\n",
    "           'money', 'relig', 'Physical', 'health', 'illness', 'wellness', 'mental',\n",
    "           'substances', 'sexual', 'food', 'death']\n",
    "\n",
    "user_df_extended1[columns] = user_df_extended1[columns].apply(pd.to_numeric, errors='coerce')\n",
    "user_df_extended1[columns] = user_df_extended1[columns].fillna(-1)\n",
    "\n",
    "# Find the top 2 highest scores for each row\n",
    "user_df_extended1[['related_1', 'related_2']] = user_df_extended1[columns].apply(find_top_two, axis=1, result_type='expand')\n",
    "\n",
    "# Drop the original columns\n",
    "user_df_extended1.drop(columns, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended1.drop('Text', axis=1, inplace=True)\n",
    "user_df_extended1.replace('E', 1, inplace=True)\n",
    "user_df_extended1['url'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'A': [1, 2, 'E', 4, 5],\n",
    "        'B': [10, 'Not a number', 30, 40, 50]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Custom function to check if a value is numeric\n",
    "def to_numeric_or_zero(value):\n",
    "    if pd.to_numeric(value, errors='coerce') is not None:\n",
    "        return pd.to_numeric(value, errors='coerce')\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the custom function to each element in the DataFrame\n",
    "user_df_extended1 = user_df_extended1.applymap(to_numeric_or_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_extended1['profile_image_url_https']=user_df_extended1['profile_image_url_https'].astype(float)\n",
    "user_df_extended1['listed_count']=user_df_extended1['listed_count'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the DataFrame's 'A' column and transform the data\n",
    "user_df_extended1['related_1'] = encoder.fit_transform(user_df_extended1['related_1'])\n",
    "user_df_extended1['related_2']= encoder.fit_transform(user_df_extended1['related_2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "id_str=user_df_extended1.id_str\n",
    "# Fit the scaler to the DataFrame and transform the data\n",
    "normalized_data = scaler.fit_transform(user_df_extended1)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=user_df_extended1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.drop(columns={\"id_str\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id_str'] + [col for col in normalized_df.columns if col != 'id_str']\n",
    "normalized_df = normalized_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.to_csv(\"/home/leanna/unfollow_prediction/Markov_chain/dataset/nodes_15csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('3.9.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8417d1dfa1d6fc0641ce57361e4c2424891a37ac2172e388282caca30e55c490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
